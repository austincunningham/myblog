(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-2d222ccc"],{cfc6:function(a,s,e){"use strict";e.r(s);var t=function(){var a=this,s=a.$createElement;a._self._c;return a._m(0)},r=[function(){var a=this,s=a.$createElement,e=a._self._c||s;return e("section",[e("h1",[a._v("Deploying Ollama on Openshift with the Ollama Operator")]),e("p",[e("img",{attrs:{src:"https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ygww6k9exujk26wkgx4j.png",alt:""}})]),e("h3",[a._v("Why Run Ollama on OpenShift?")]),e("p",[a._v("Running Ollama on OpenShift gives you a scalable, centralized service that's ready for team collaboration and production workloads.")]),e("p",[a._v("The Ollama Operator makes it incredibly easy to deploy and manage Ollama instances on a cluster. This guide will walk you through the process, from installing the operator to testing your deployed Ollama service.")]),e("h3",[a._v("What is the Ollama Operator?")]),e("p",[a._v("The Ollama Operator is designed to streamline the deployment and management of Ollama on Kubernetes and OpenShift clusters. It automates tasks like creating necessary resources, managing deployments, and ensuring your Ollama inference server is up and running.")]),e("p",[a._v("You can find the ollama operator's repository "),e("a",{attrs:{href:"https://github.com/opendatahub-io/llama-stack-k8s-operator/tree/odh"}},[a._v("on github")]),a._v(".")]),e("h2",[a._v("Install the Operator")]),e("p",[a._v("First, let's install the Ollama Operator itself. This will create a new project/namespace (llama-stack-k8s-operator-system) for Ollama and then apply the operator's manifest.")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("oc apply -f https://raw.githubusercontent.com/llamastack/llama-stack-k8s-operator/main/release/operator.yaml\n")])]),e("p",[a._v("You should see output similar to this, indicating the creation of various Kubernetes resources:")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("namespace/llama-stack-k8s-operator-system created\ncustomresourcedefinition.apiextensions.k8s.io/llamastackdistributions.llamastack.io created\nserviceaccount/llama-stack-k8s-operator-controller-manager created\nrole.rbac.authorization.k8s.io/llama-stack-k8s-operator-leader-election-role created\nclusterrole.rbac.authorization.k8s.io/llama-stack-k8s-operator-manager-role created\nclusterrole.rbac.authorization.k8s.io/llama-stack-k8s-operator-metrics-reader created\nclusterrole.rbac.authorization.k8s.io/llama-stack-k8s-operator-proxy-role created\nrolebinding.rbac.authorization.k8s.io/llama-stack-k8s-operator-leader-election-rolebinding created\nclusterrolebinding.rbac.authorization.k8s.io/llama-stack-k8s-operator-manager-rolebinding created\nclusterrolebinding.rbac.authorization.k8s.io/llama-stack-k8s-operator-proxy-rolebinding created\nconfigmap/llama-stack-k8s-operator-manager-config created\nservice/llama-stack-k8s-operator-controller-manager-metrics-service created\ndeployment.apps/llama-stack-k8s-operator-controller-manager created\n")])]),e("p",[a._v("This confirms that the operator has been successfully deployed to the llama-stack-k8s-operator-system namespace.")]),e("h3",[a._v("Run the Quickstart Script")]),e("p",[a._v("Now that the operator is running, we can use a convenient quickstart script provided in the operator's repository to deploy an Ollama instance.")]),e("p",[a._v("Clone the Repository")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("git "),e("span",{pre:!0,attrs:{class:"hljs-built_in"}},[a._v("clone")]),a._v(" https://github.com/opendatahub-io/llama-stack-k8s-operator.git\n")])]),e("p",[a._v("Navigate to the Repository Directory")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[e("span",{pre:!0,attrs:{class:"hljs-built_in"}},[a._v("cd")]),a._v(" llama-stack-k8s-operator\n")])]),e("p",[a._v("Execute the Quickstart Script "),e("code",{pre:!0},[a._v("./hack/deploy-quickstart.sh")]),a._v("\nThe script will create a new namespace (ollama-dist) and deploy Ollama as a provider. It will also handle necessary OpenShift security context constraints (SCCs) if you're on OpenShift.")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("./hack/deploy-quickstart.sh\nChecking "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("if")]),a._v(" namespace ollama-dist exists...\nCreating namespace ollama-dist...\nnamespace/ollama-dist created\nStart deploying ollama as provider with configuration:\n  ServingRuntime Image: ollama/ollama:latest\n  Inference Server: ollama\n  Model: llama3.2:1b\nChecking "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("if")]),a._v(" ServiceAccount ollama-sa exists...\nCreating ServiceAccount ollama-sa...\nserviceaccount/ollama-sa created\nChecking "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("if")]),a._v(" OpenShift prerequisites exist "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("in")]),a._v(" namespace: ollama-dist "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("for")]),a._v(" service account: ollama-sa...\nCreating ollama-scc, ollama-scc-role and ollama-scc-rolebinding "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("for")]),a._v(" ollama-sa\nsecuritycontextconstraints.security.openshift.io/ollama-scc created\nrole.rbac.authorization.k8s.io/ollama-scc-role created\nrolebinding.rbac.authorization.k8s.io/ollama-scc-rolebinding created\nAnnotating ServiceAccount to clarify that it uses ollama-scc...\nserviceaccount/ollama-sa annotate\nCreating ollama-server deployment and service with image: ollama/ollama:latest...\ndeployment.apps/ollama-server created\nservice/ollama-server-service created\nThis may take up to 5 minutes "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("for")]),a._v(" the image to be pulled and container to start...\nWaiting "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("for")]),a._v(" deployment "),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"ollama-server"')]),a._v(" rollout to finish: 0 of 1 updated replicas are available...\ndeployment "),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"ollama-server"')]),a._v(" successfully rolled out\nDeployment is ready!\nollama inference server is now running!\n  Namespace: ollama-dist\n  Service: ollama-server-service\n  Port: 11434\nAccess at:\n  http://ollama-server-service.ollama-dist.svc.cluster.local:11434\n")])]),e("p",[a._v("The script will wait for the ollama-server deployment to be ready, which may take a few minutes as the Ollama image (ollama/ollama:latest) and the llama3.2:1b model are pulled.")]),e("h2",[a._v("Test the Ollama Service")]),e("p",[a._v("Once the deployment is ready, you can test if Ollama is working correctly.")]),e("h3",[a._v("Port Forward the Ollama Service")]),e("p",[a._v("To access the Ollama service from your local machine, port-forward it:")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("oc port-forward -n ollama-dist svc/ollama-server-service 11434:11434\n")])]),e("p",[a._v("This command will forward local port 11434 to the Ollama service inside your cluster. You'll see output similar to:")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("Forwarding from [::1]:11434 -> 11434\nHandling connection "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("for")]),a._v(" 11434\nHandling connection "),e("span",{pre:!0,attrs:{class:"hljs-keyword"}},[a._v("for")]),a._v(" 11434\n")])]),e("p",[a._v("Keep this command running in a separate terminal.")]),e("h3",[a._v("Test the /api/tags Endpoint")]),e("p",[a._v("Now, open another terminal and test the "),e("code",{pre:!0},[a._v("/api/tags")]),a._v(" endpoint to see the models available:")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("curl http://localhost:11434/api/tags\n")])]),e("p",[a._v("You should receive a JSON response showing the llama3.2:1b model that was deployed:")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-json"}},[a._v("{"),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"models"')]),a._v(":[{"),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"name"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"llama3.2:1b"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"model"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"llama3.2:1b"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"modified_at"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"2025-07-31T09:31:39.9132431Z"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"size"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1321098329")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"digest"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"baf6a787fdffd633537aa2eb51cfd54cb93ff08e28040095462bb63daf552878"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"details"')]),a._v(":{"),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"parent_model"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('""')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"format"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"gguf"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"family"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"llama"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"families"')]),a._v(":["),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"llama"')]),a._v("],"),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"parameter_size"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"1.2B"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"quantization_level"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"Q8_0"')]),a._v("}}}]}\n")])]),e("h3",[a._v("Test the /api/generate Endpoint")]),e("p",[a._v("Finally, let's test the "),e("code",{pre:!0},[a._v("/api/generate")]),a._v(" endpoint to interact with the model:")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("curl -X POST http://localhost:11434/api/generate \\\n  -H "),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"Content-Type: application/json"')]),a._v(" \\\n  -d "),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('\'{\n    "model": "llama3.2:1b",\n    "prompt": "Hello, how are you?",\n    "stream": false\n  }\'')]),a._v("\n")])]),e("p",[a._v("You should receive a JSON response showing the api chat response")]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-json"}},[a._v("{"),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"model"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"llama3.2:1b"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"created_at"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"2025-07-31T09:42:46.926734668Z"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"response"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"I\'m doing well, thank you for asking. Is there anything I can help you with or would you like to talk about something in particular?"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"done"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-literal"}},[a._v("true")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"done_reason"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-string"}},[a._v('"stop"')]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"context"')]),a._v(":["),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128006")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("9125")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128007")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("271")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("38766")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1303")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("33025")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("2696")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("25")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("6790")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("220")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("2366")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("18")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("271")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128009")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128006")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("882")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128007")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("271")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("9906")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("11")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1268")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("527")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("499")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("30")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128009")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128006")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("78191")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("128007")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("271")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("40")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("2846")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("3815")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1664")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("11")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("9901")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("499")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("369")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("10371")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("13")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("2209")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1070")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("4205")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("358")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("649")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1520")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("499")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("449")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("477")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1053")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("499")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("1093")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("311")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("3137")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("922")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("2555")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("304")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("4040")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("30")]),a._v("],"),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"total_duration"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("5444261976")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"load_duration"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("2251218959")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"prompt_eval_count"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("31")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"prompt_eval_duration"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("734841277")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"eval_count"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("30")]),a._v(","),e("span",{pre:!0,attrs:{class:"hljs-attr"}},[a._v('"eval_duration"')]),a._v(":"),e("span",{pre:!0,attrs:{class:"hljs-number"}},[a._v("2457145861")]),a._v("}\n")])]),e("h2",[a._v("Conclusion and Next Steps")]),e("p",[a._v("You have successfully deployed a fully functional and scalable Ollama inference server on your OpenShift cluster. By using the Ollama Operator, you've bypassed complex manual setup and now have a robust service ready to be integrated into your projects.")]),e("p",[a._v("So, what's next? Here are a few ideas to explore:")]),e("ul",[e("li",[e("strong",[a._v("Try Different Models:")]),a._v(" Explore the "),e("a",{attrs:{href:"https://ollama.com/search"}},[a._v("Ollama model library")]),a._v(" for other models. The quickstart deployed llama3.2:1b, but you can easily try others with the --provider and --model flags. e.g.")])]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("./hack/deploy-quickstart.sh --provider ollama --model mistral:latest\n")])]),e("blockquote",[e("p",[e("strong",[a._v("NOTE:")]),a._v(" llama3.2:1b is a small model other models may take longer to deploy")])]),e("ul",[e("li",[e("strong",[a._v("Expose Your Service:")]),a._v(" Instead of using port-forward, create an OpenShift Route to expose your Ollama service with a public URL. This makes it accessible to external applications and users. You can do this with a simple command:")])]),e("pre",{pre:!0},[e("code",{pre:!0,attrs:{"v-pre":"",class:"language-bash"}},[a._v("oc expose svc/ollama-server-service -n ollama-dist\n")])]),e("ul",[e("li",[e("p",[e("strong",[a._v("Integrate with an Application:")]),a._v(" Now that you have a stable API endpoint, connect it to your own applications. Whether it's a RAG (Retrieval-Augmented Generation) pipeline, a custom chatbot, or an automation script, your Ollama service is ready to power it.")])]),e("li",[e("p",[e("strong",[a._v("Explore the Operator:")]),a._v(" Dive deeper into the "),e("a",{attrs:{href:"https://github.com/opendatahub-io/llama-stack-k8s-operator/blob/odh/README.md"}},[a._v("Ollama Operator's documentation")]),a._v(" to understand its features, such as managing multiple models and custom configurations.")])])])])}],l=e("2877"),n={},o=Object(l["a"])(n,t,r,!1,null,null,null);s["default"]=o.exports}}]);
//# sourceMappingURL=chunk-2d222ccc.a6b3e12b.js.map